---
import Layout from '../../layouts/Layout.astro'
import Nav from '../../components/Nav.astro'
import Code from '../../components/Code.astro'
---
<Layout
  title="Guides"
  description="How to fan out prompts, poll with backoff, use system prompts, and integrate chomp as an agent tool."
  path="/docs/guides"
  type="article"
  keywords="how-to, guides, fan out, rate limits, system prompts, agent"
>
  <Nav active="/docs/guides" />
  <main class="max-w-3xl mx-auto px-5 py-12">
    <div class="text-sm font-semibold text-green-500 mb-2">How-to guides</div>
    <h1 class="text-3xl font-bold tracking-tight mb-2">Guides</h1>
    <p class="text-zinc-500 dark:text-zinc-400 mb-10">Practical recipes for real problems.</p>

    <section class="space-y-12">

      <div>
        <h2 class="text-xl font-bold mb-3">How to fan out a prompt across multiple models</h2>
        <p class="text-zinc-600 dark:text-zinc-400 mb-3">Dispatch the same prompt to several models in parallel, then compare responses.</p>
        <Code code={`#!/bin/bash
MODELS=("stepfun/step-3.5-flash:free" "deepseek/deepseek-r1-0528:free" "arcee-ai/trinity-large-preview:free")
PROMPT="Explain the CAP theorem in 2 sentences."

# Dispatch all in parallel
for model in "$" {MODELS[@]}""; do
  curl -s -X POST https://chomp.coey.dev/api/dispatch \\
    -H "Authorization: Bearer $CHOMP_TOKEN" \\
    -H "Content-Type: application/json" \\
    -d "{\\"prompt\\": \\"$PROMPT\\", \\"model\\": \\"$model\\"}" &amp;
done
wait`} />
        <p class="mt-3 text-zinc-600 dark:text-zinc-400">Each dispatch returns immediately. Poll all job IDs until all are <code class="bg-zinc-200 dark:bg-zinc-800 px-1.5 py-0.5 rounded text-sm">done</code>, then compare results.</p>
      </div>

      <div>
        <h2 class="text-xl font-bold mb-3">How to poll with retry and backoff</h2>
        <p class="text-zinc-600 dark:text-zinc-400 mb-3">Some models (especially reasoning models like DeepSeek R1) take 30–60 seconds.</p>
        <Code code={`#!/bin/bash\nJOB_ID="$1"\nDELAY=2\n\nwhile true; do\n  RESULT=$(curl -s https://chomp.coey.dev/api/result/$JOB_ID \\\n    -H "Authorization: Bearer $CHOMP_TOKEN")\n  STATUS=$(echo "$RESULT" | jq -r .status)\n\n  case $STATUS in\n    done)  echo "$RESULT" | jq -r .result; exit 0 ;;\n    error) echo "$RESULT" | jq -r .error; exit 1 ;;\n    *)     sleep $DELAY; DELAY=$((DELAY * 2 > 30 ? 30 : DELAY * 2)) ;;\n  esac\ndone`} />
      </div>

      <div>
        <h2 class="text-xl font-bold mb-3">How to use a system prompt</h2>
        <p class="text-zinc-600 dark:text-zinc-400 mb-3">Steer model behavior with a system message. Useful for constraining output format.</p>
        <Code code={`curl -X POST https://chomp.coey.dev/api/dispatch \\
  -H "Authorization: Bearer $CHOMP_TOKEN" \\
  -H "Content-Type: application/json" \\
  -d '{\n    "system": "Reply only in valid JSON.",\n    "prompt": "List 3 sorting algorithms with time complexity."\n  }'`} />
      </div>

      <div>
        <h2 class="text-xl font-bold mb-3">How to use chomp as an agent’s tool</h2>
        <p class="text-zinc-600 dark:text-zinc-400 mb-3">An orchestrating agent can delegate subtasks to free models to preserve its own context window.</p>
        <Code code={`# Dispatch a bounded subtask\nJOB=$(curl -s -X POST https://chomp.coey.dev/api/dispatch \\
  -H "Authorization: Bearer $CHOMP_TOKEN" \\
  -H "Content-Type: application/json" \\
  -d '{"system": "Summarize in 3 bullet points.",\n       "prompt": "...file contents here..."}')\n\nJOB_ID=$(echo $JOB | jq -r .id)\n\n# Poll, then inject result into the agent context\nsleep 10\ncurl -s https://chomp.coey.dev/api/result/$JOB_ID \\
  -H "Authorization: Bearer $CHOMP_TOKEN" | jq -r .result`} />
        <p class="mt-3 text-zinc-600 dark:text-zinc-400">The orchestrator only sees the 3-bullet summary, not the entire file. Context preserved.</p>
      </div>

    </section>
  </main>
</Layout>
